## Anicca 对话技术路径（Branch + Synthesis）

本文件在既有《1_新TECHNICAL_IMPLEMENTATION_PATH.md》的渲染/交互骨架上，给出“正/反/合”的对话技术实现路径：包括整体架构、数据 Schema、上下文供给策略、API 设计、示例代码、与 Shader/UI 的集成、性能与成本控制、监控与安全等。

—

### 1. 指导思想
- **单请求 → 双分支（Thesis/Antithesis）**：默认一次调用同时产出两颗胶囊，前端分两泡展示，最省 token、最稳。
- **滑动摘要 + 相关检索**：不堆叠全文历史，只提供“滚动摘要 + Top‑K 胶囊要点”，在成本可控的前提下保持上下文连贯。
- **统一 JSON Schema（Structured Outputs）**：用 Responses API 的 `response_format: { type: "json_schema" }` 约束输出，确保可直接落到业务实体。
- **条件触发“合”**：仅在 UI/逻辑判定满足“合”的前提时二次调用生成合胶囊，记录来源与对齐规则。

—

### 2. 系统架构（对话域）
```
┌─────────────────────────────────────────────────────────┐
│                    Dialogue Orchestrator                │
├─────────────────────────────────────────────────────────┤
│  Context Manager   │  Branch Generator  │  Synthesis    │
│ (Summary+Retrieval)│ (Dual Capsules)    │  Engine       │
├─────────────────────────────────────────────────────────┤
│   Storage/Index    │   API Routes (/api/branches, /api/synthesis)    │
├─────────────────────────────────────────────────────────┤
│      Rendering Bridge → Shader/UI (Shader3Canvas, splitProgress)     │
└─────────────────────────────────────────────────────────┘
```

- 与现有 `Shader3Canvas.tsx`、`shader3.ts` 的关系：
  - 对话域仅输出结构化“胶囊”（正/反/合），并通过前端状态驱动 `splitProgress`、边界亮度/粗糙度、合流编舞。
  - Shader 层不持久化语义，所有 lineage/fork/graft/合 的谱系管理在 JS 层完成。

—

### 3. 胶囊数据 Schema（统一约束）
```json
{
  "type": "object",
  "properties": {
    "id": { "type": "string" },
    "parent_ids": { "type": "array", "items": { "type": "string" } },
    "stance": { "type": "string", "enum": ["thesis", "antithesis", "synthesis"] },
    "summary": { "type": "string" },
    "assumptions": { "type": "array", "items": { "type": "string" } },
    "keywords": { "type": "array", "items": { "type": "string" } },
    "lineage": { "type": "string" },
    "created_at": { "type": "string" },
    "seed": { "type": "number" },
    "temperature": { "type": "number" },
    "model": { "type": "string" },
    "prompt_hash": { "type": "string" }
  },
  "required": ["id", "stance", "summary", "created_at"]
}
```

- 双分支打包：
```json
{
  "type": "object",
  "properties": {
    "thesis": { "$ref": "#/Capsule" },
    "antithesis": { "$ref": "#/Capsule" }
  },
  "required": ["thesis", "antithesis"]
}
```

—

### 4. 上下文供给策略（成本友好）
- **滚动摘要（Sliding Summary）**：
  - 维持 ≤120 字的跨轮摘要，包含：当前主题、边界/前提、未决问题。
  - 每轮更新，供下一次请求使用。
- **Top‑K 检索（Selective Retrieval）**：
  - 对历史胶囊建立 embeddings（仅索引 `summary/assumptions/keywords`）。
  - 每轮检索相关度最高的 3–6 条要点（每条 ≤120 字）。
- **提示词拼接**：
  - 将“滚动摘要 + 要点 + 当前输入”拼为一次上下文，避免堆叠全文历史。

—

### 5. API 设计
- `POST /api/branches`
  - 入参：`{ userInput, rollingSummary, retrievedCapsuleBullets, parentIds }`
  - 出参：`{ thesis: Capsule, antithesis: Capsule }`
  - 策略：默认“单请求 → 双分支”，必要时支持并行双请求（差异化温度）。

- `POST /api/synthesis`
  - 入参：`{ thesis: Capsule, antithesis: Capsule }`
  - 出参：`{ synthesis: Capsule }`
  - 策略：仅在满足 UI/逻辑“合”条件时调用。

—

### 6. 服务端最小实现（示例，Node/Next.js Route Handler）
```ts
// 文件示例：src/app/api/branches/route.ts
import OpenAI from "openai";
import { NextRequest, NextResponse } from "next/server";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// 双胶囊 Schema（用于 Structured Outputs）
const dualCapsuleSchema = {
  type: "object",
  properties: {
    thesis: capsuleSchema(),
    antithesis: capsuleSchema()
  },
  required: ["thesis", "antithesis"]
};

function capsuleSchema() {
  return {
    type: "object",
    properties: {
      id: { type: "string" },
      parent_ids: { type: "array", items: { type: "string" } },
      stance: { type: "string", enum: ["thesis", "antithesis", "synthesis"] },
      summary: { type: "string" },
      assumptions: { type: "array", items: { type: "string" } },
      keywords: { type: "array", items: { type: "string" } },
      lineage: { type: "string" },
      created_at: { type: "string" },
      seed: { type: "number" },
      temperature: { type: "number" },
      model: { type: "string" },
      prompt_hash: { type: "string" }
    },
    required: ["id", "stance", "summary", "created_at"]
  } as const;
}

export async function POST(req: NextRequest) {
  try {
    const body = await req.json();
    const { userInput, rollingSummary, retrievedCapsuleBullets, parentIds } = body ?? {};

    if (!userInput) {
      return NextResponse.json({ error: "userInput required" }, { status: 400 });
    }

    const promptContext = [
      `对话滚动摘要：${rollingSummary || "（无）"}`,
      retrievedCapsuleBullets?.length ? `相关要点：\n- ${retrievedCapsuleBullets.join("\n- ")}` : "相关要点：（无）",
      `当前输入：${userInput}`,
      `任务：同时生成 Thesis（顺流延展）与 Antithesis（最强反质）两颗胶囊。parent_ids = ${JSON.stringify(parentIds || [])}。`
    ].join("\n\n");

    // 单请求 → 双分支
    const temperature = 0.7; // 默认适中温度
    const model = process.env.ANICCA_DEFAULT_MODEL || "gpt-4o-mini";

    const res = await openai.responses.create({
      model,
      input: [
        "你是一个分形对话引擎，负责同时生成 Thesis 与 Antithesis。",
        "要求：1) Thesis = 顺流延展；2) Antithesis = 最强反质；",
        "两者必须输出结构化JSON胶囊，字段详见 schema。",
        promptContext
      ].join("\n"),
      response_format: { type: "json_schema", json_schema: { name: "DualCapsule", schema: dualCapsuleSchema } },
      temperature,
      max_output_tokens: 1024
    });

    // 说明：使用 Structured Outputs 时，SDK 将直接提供结构化字段；
    // 具体取值路径以 SDK 版本为准（可包一层 read helper 来屏蔽差异）。
    const dual = res.output?.[0]?.content?.[0]?.json ?? res;

    // 追加运行时元数据（便于回放/审计）
    if (dual?.thesis) {
      dual.thesis.temperature = temperature;
      dual.thesis.model = model;
    }
    if (dual?.antithesis) {
      dual.antithesis.temperature = temperature;
      dual.antithesis.model = model;
    }

    return NextResponse.json(dual);
  } catch (error: any) {
    // 关键错误打印 + 友好返回
    console.error("/api/branches error", { message: error?.message, stack: error?.stack });
    return NextResponse.json({ error: "branches_failed" }, { status: 500 });
  }
}
```

```ts
// 文件示例：src/app/api/synthesis/route.ts
import OpenAI from "openai";
import { NextRequest, NextResponse } from "next/server";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const capsuleSchema = {
  type: "object",
  properties: {
    id: { type: "string" },
    parent_ids: { type: "array", items: { type: "string" } },
    stance: { type: "string", enum: ["thesis", "antithesis", "synthesis"] },
    summary: { type: "string" },
    assumptions: { type: "array", items: { type: "string" } },
    keywords: { type: "array", items: { type: "string" } },
    lineage: { type: "string" },
    created_at: { type: "string" },
    seed: { type: "number" },
    temperature: { type: "number" },
    model: { type: "string" },
    prompt_hash: { type: "string" }
  },
  required: ["id", "stance", "summary", "created_at"]
} as const;

export async function POST(req: NextRequest) {
  try {
    const body = await req.json();
    const { thesis, antithesis } = body ?? {};
    if (!thesis || !antithesis) {
      return NextResponse.json({ error: "thesis/antithesis required" }, { status: 400 });
    }

    const model = process.env.ANICCA_STRICT_MODEL || "o4-mini";
    const temperature = 0.3; // 合题更可复现

    const res = await openai.responses.create({
      model,
      input: [
        "根据以下正/反胶囊，生成合（Synthesis）胶囊：",
        `Thesis: ${JSON.stringify(thesis)}`,
        `Antithesis: ${JSON.stringify(antithesis)}`,
        "要求：标注来源分支、对齐规则、让步点、适用域，输出为结构化JSON胶囊。"
      ].join("\n"),
      response_format: { type: "json_schema", json_schema: { name: "Capsule", schema: capsuleSchema } },
      temperature,
      max_output_tokens: 1024
    });

    const synthesis = res.output?.[0]?.content?.[0]?.json ?? res;
    if (synthesis) {
      synthesis.temperature = temperature;
      synthesis.model = model;
    }

    return NextResponse.json({ synthesis });
  } catch (error: any) {
    console.error("/api/synthesis error", { message: error?.message, stack: error?.stack });
    return NextResponse.json({ error: "synthesis_failed" }, { status: 500 });
  }
}
```

—

### 7. 前端对接与 Shader 编舞
- 渲染桥接：
  - 调用 `/api/branches` 后，拿到 `{ thesis, antithesis }`：
    - 建立两泡的 UI 节点，写入其 `capsuleId/stance/summary/...`；
    - 以到达顺序或并发流驱动 `splitProgress`，映射边界亮度/粗糙度与光晕；
  - 当用户选择其中一泡作为“主念”递归：将该 `id` 推入下一轮 `parentIds`。
  - 当判定可“合”时：调用 `/api/synthesis`，合流动画三步：靠拢 → 对齐闪烁 → 边界消隐。

- 事件/状态：
  - JS 层维护会话树（DAG）：`node = capsuleId`，边为 `parent_ids`。
  - 记录 `seed/temperature/model/prompt_hash`，可回放/对比不同口径。

—

### 8. Embeddings 与检索
- 模型：轻量级（如同级别于 `text-embedding-3-small`）。
- 索引字段：`summary/assumptions/keywords`。
- 检索：Top‑K = 3–6；仅回传“要点句”，限制长度避免提示词膨胀。

—

### 9. 性能与成本控制
- `max_output_tokens`：建议 512–1024 上限。
- 温度策略：默认 0.6–0.8；增强对置改走并行双请求（Thesis 0.2–0.4，Antithesis 0.9–1.0）。
- 并行与流式：
  - 省 token/稳定：单请求双分支，一次性渲染。
  - 更强编舞：并行双请求+SSE，分别驱动两泡的到达与光晕节奏。
- 重试与退避：指数退避（上限 2–3 次），失败时回退为“上轮摘要+要点”的轻响应。

—

### 10. 监控、日志与安全
- 日志（服务端）：记录 `capsule_id, parent_ids, model, temperature, seed, prompt_hash, cost估算, duration`。
- 追踪：为提示词计算 `prompt_hash`（如 SHA-256），便于比对输出差异。
- 安全：
  - API Key 仅服务端保存；Next.js Route Handler/Server Action 调用；客户端绝不直连。
  - 限流与速率限制；异常监控（Sentry 同类）。
  - 审计：输入/输出可存时间戳与 hash（不存敏感原文）。

—

### 11. 失败与边界处理（try-catch 强化）
- 所有外部调用与 JSON 解析均包裹 try-catch，返回友好错误码（如 `branches_failed`）。
- 降级策略：
  - 超时/限流 → 降级到更便宜或更快模型，或复用上轮结果。
  - 结构化校验失败 → 回退为“简单文本摘要”，并提示前端采用朴素气泡样式。

—

### 12. 与现有文件/模块的衔接
- `src/components/Shader3Canvas.tsx`：
  - 新增对 `/api/branches` 的调用与结果映射；
  - 用返回的两胶囊驱动分形动画（`splitProgress`）。
- `src/store/graph.ts`：
  - 扩展为会话 DAG：节点 = 胶囊；边 = `parent_ids`；提供 lineage 查询与回放。
- `src/shaders/shader3.ts`：
  - 保持视觉参数接口不变；从 UI 层注入 `splitProgress/brightness/roughness` 等。

—

### 13. 渐进路线（对话域）
1) MVP：单请求双分支 + 本地 JSON/IndexedDB 存储 + 轻检索（内存向量/简化相似度）。
2) 强化：引入小型向量库（如本地 HNSW/SQLite 插件），增加谱系可视化与跨域嫁接辅助。
3) 进阶：并行双请求 + SSE 流式编舞，完善监控/限流/成本看板。

—

### 14. 成本预估（示意）
- 单轮请求（双分支）：
  - 上下文：滚动摘要（≤120字）+ 要点 3–6 条 + 当前输入 → 通常 < 1–2k tokens。
  - 输出：两个胶囊（短摘要/要点） → 通常 < 400–800 tokens。
  - 合：仅在触发条件满足时追加一次请求。

—

### 15. 小结
- 官方 API/SDK 不提供“branch 对象”，分支树需自管；
- “单请求双分支 + 滑动摘要 + 检索 + 统一 Schema”是当前最优工程解；
- 通过 Route Handler + Structured Outputs + 轻检索，能与现有 Shader 编舞顺畅耦合，低成本实现“呼吸式分形对话”。

—

### 16. 版本兼容与返回体差异
- SDK 版本建议：`openai` (Node) ≥ 1.14.x（或文档当前推荐版本）。
- Structured Outputs 取值差异：
  - 新版：`const parsed = res.output_parsed;`
  - 旧版（或部分实现）：`const parsed = res.output?.[0]?.content?.[0]?.json;`
- 建议封装 helper：
```ts
function readOutputParsed(res: any) {
  // 新版优先
  if (res && res.output_parsed) return res.output_parsed;
  // 兼容旧路径
  const legacy = res?.output?.[0]?.content?.[0]?.json;
  if (legacy) return legacy;
  // 兜底：直接返回（让上层再判断）
  return res;
}
```

—

### 17. Prompt Hash 生成与验证模板
- 生成时机：完成“滚动摘要 + Top‑K 要点 + 当前输入”的拼接后，再计算 SHA‑256；这样能精确追踪上下文的任何微调。
- 建议字段：`{ prompt_hash, model, temperature, seed, created_at }`。
```ts
import crypto from "crypto";

export function computePromptHash(promptContext: string): string {
  try {
    return crypto.createHash("sha256").update(promptContext, "utf8").digest("hex");
  } catch (e) {
    // 失败时返回空串，日志上报
    console.error("computePromptHash error", e);
    return "";
  }
}
```

—

### 18. /api/synthesis 多模型 Fallback 策略
- 目标：在限流/超时/结构化失败等情况下，保证“合”可退化产出与成本可控。
- 策略阶梯：
  1) 首选：较强推理模型（如 `o4-mini`），`temperature=0.3`，`max_output_tokens=1024`；
  2) 失败 → 降级到通用模型（如 `gpt-4o-mini`），同样走 Structured Outputs；
  3) 仍失败 → 退化为“Minimal Synthesis 文本摘要”（不结构化），长度 ≤ 200 字，前端采用朴素视觉；
  4) 最终失败 → 返回 `synthesis_failed` 错误码，前端展示“合流未就绪，可稍后重试”。

```ts
async function callSynthesisWithFallback(payload: any) {
  const primaryModel = process.env.ANICCA_STRICT_MODEL || "o4-mini";
  const fallbackModel = process.env.ANICCA_DEFAULT_MODEL || "gpt-4o-mini";

  try {
    return await callSynthesis(primaryModel, payload, 0.3);
  } catch (e1) {
    console.warn("synthesis primary failed, fallback", e1);
    try {
      return await callSynthesis(fallbackModel, payload, 0.4);
    } catch (e2) {
      console.warn("synthesis fallback failed, degrade to minimal text", e2);
      return { minimalText: buildMinimalSynthesisText(payload) }; // 前端据此走简化样式
    }
  }
}
```

—

### 19. Synthesis 提示词的去冗余指令
- 为避免“回显两段摘要+套话”，在合题提示词中加入：
  - “若正反观点高度重合，则输出 minimal synthesis（仅保留关键共识与一个清晰的边界）”；
  - “不得重复粘贴 Thesis/Antithesis 的原句，如需引用请压缩为要点”；
  - “输出必须严格遵循 Schema；若无法满足对齐条件，返回 minimal 版本并标注原因”。


